{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72115483",
   "metadata": {},
   "source": [
    "Load huggingface api tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "330db85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "HF_API_TOKEN = open(\"../credentials/huggingface.key.txt\").read().replace(\"\\n\", \"\").replace(\" \", \"\")\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HF_API_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062bba5d",
   "metadata": {},
   "source": [
    "Setup inference api for UL2 and T5-XXL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3049517c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub.inference_api import InferenceApi\n",
    "\n",
    "# Flan-UL2 20B\n",
    "inference_flan_ul2 = InferenceApi(repo_id=\"google/flan-ul2\", token=HF_API_TOKEN)\n",
    "# Flan-T5-XXL 11B\n",
    "inference_flan_t5_xxl = InferenceApi(repo_id=\"google/flan-t5-xxl\", token=HF_API_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ced2284",
   "metadata": {},
   "source": [
    "## Question Answering from Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a55dda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredFileLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b56832c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = \"\"\"\n",
    "Install the Python SDK with pip install \"unstructured[local-inference]\" - If you do not need to process PDFs or images, you can run pip install unstructured\n",
    "Install the following system dependencies if they are not already available on your system. Depending on what document types you're parsing, you may not need all of these.\n",
    "libmagic-dev (filetype detection)\n",
    "poppler-utils (images and PDFs)\n",
    "tesseract-ocr (images and PDFs)\n",
    "libreoffice (MS Office docs)\n",
    "If you are parsing PDFs, run the following to install the detectron2 model, which unstructured uses for layout detection:\n",
    "pip install \"detectron2@git+https://github.com/facebookresearch/detectron2.git@e2ce8dc#egg=detectron2\"\n",
    "\"\"\"\n",
    "\n",
    "doc2 = \"\"\"\n",
    "By default, Chains and Agents are stateless, meaning that they treat each incoming query independently.\n",
    "In some applications (chatbots being a GREAT example) it is highly important to remember previous interactions, both at a short term but also at a long term level.\n",
    "The concept of \"Memory\" exists to do exactly that.\n",
    "\"\"\"\n",
    "\n",
    "doc3 = \"\"\"\n",
    "Chroma lets you manage collections of embeddings, using the collection primitive.\n",
    "\n",
    "Creating, inspecting, and deleting Collections\n",
    "Chroma uses collection names in the url, so there are a few restrictions on naming them:\n",
    "\n",
    "The length of the name must be between 3 and 63 characters.\n",
    "The name must start and end with a lowercase letter or a digit, and it can contain dots, dashes, and underscores in between.\n",
    "The name must not contain two consecutive dots.\n",
    "The name must not be a valid IP address.\n",
    "\"\"\"\n",
    "\n",
    "doc = doc1 + \"\\n\\n\" + doc2 + \"\\n\\n\" + doc3\n",
    "with open(\"doc.txt\", \"w\") as f:\n",
    "    f.write(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fef0d678",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredFileLoader(\"doc.txt\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2780da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Install the Python SDK with pip install \"unstructured[local-inference]\" - If you do not need to process PDFs or images, you can run pip install unstructured Install the following system dependencies if they are not already available on your system. Depending on what document types you\\'re parsing, you may not need all of these. libmagic-dev (filetype detection) poppler-utils (images and PDFs) tesseract-ocr (images and PDFs) libreoffice (MS Office docs) If you are parsing PDFs, run the following to install the detectron2 model, which unstructured uses for layout detection: pip install \"detectron2@git+https://github.com/facebookresearch/detectron2.git@e2ce8dc#egg=detectron2\"\\n\\nBy default, Chains and Agents are stateless, meaning that they treat each incoming query independently. In some applications (chatbots being a GREAT example) it is highly important to remember previous interactions, both at a short term but also at a long term level. The concept of \"Memory\" exists to do exactly that.\\n\\nChroma lets you manage collections of embeddings, using the collection primitive.\\n\\nCreating, inspecting, and deleting Collections Chroma uses collection names in the url, so there are a few restrictions on naming them:\\n\\nThe length of the name must be between 3 and 63 characters. The name must start and end with a lowercase letter or a digit, and it can contain dots, dashes, and underscores in between. The name must not contain two consecutive dots. The name must not be a valid IP address.', metadata={'source': 'doc.txt'})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cffec98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.embeddings import HuggingFaceHubEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.chains import VectorDBQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77e336f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suriya/p23/llm-benchmarks/env-torch_310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "flan_ul2 = HuggingFaceHub(repo_id=\"google/flan-ul2\", model_kwargs={\"temperature\": 0.1, \"max_new_tokens\": 256})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae10830f",
   "metadata": {},
   "source": [
    "Perform document similarity search comparing embeddings generated from online vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e607a4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 680, which is longer than the specified 150\n",
      "Created a chunk of size 318, which is longer than the specified 150\n",
      "You're using a different task than the one specified in the repository. Be sure to know what you're doing :)\n",
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=150, chunk_overlap=0)\n",
    "texts = text_splitter.split_text(docs[0].page_content)\n",
    "embeddings = HuggingFaceHubEmbeddings()\n",
    "docsearch = Chroma.from_texts(texts, embeddings, metadatas=[{\"source\": str(i)} for i in range(len(texts))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f3f933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_with_sources_chain(flan_ul2, chain_type=\"refine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbc98204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 251 ms, sys: 898 µs, total: 252 ms\n",
      "Wall time: 5.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_documents': [Document(page_content='The length of the name must be between 3 and 63 characters. The name must start and end with a lowercase letter or a digit, and it can contain dots, dashes, and underscores in between. The name must not contain two consecutive dots. The name must not be a valid IP address.', metadata={'source': '4'}),\n",
       "  Document(page_content='Creating, inspecting, and deleting Collections Chroma uses collection names in the url, so there are a few restrictions on naming them:', metadata={'source': '3'}),\n",
       "  Document(page_content='By default, Chains and Agents are stateless, meaning that they treat each incoming query independently. In some applications (chatbots being a GREAT example) it is highly important to remember previous interactions, both at a short term but also at a long term level. The concept of \"Memory\" exists to do exactly that.', metadata={'source': '1'}),\n",
       "  Document(page_content='Chroma lets you manage collections of embeddings, using the collection primitive.', metadata={'source': '2'})],\n",
       " 'question': 'A name cannot be ________?',\n",
       " 'output_text': 'a valid IP address'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "question = \"A name cannot be ________?\"\n",
    "docs = docsearch.similarity_search(question)\n",
    "chain({\"input_documents\" : docs, \"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c981274",
   "metadata": {},
   "source": [
    "> \"What are the rules for a name?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4b9baf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 256 ms, sys: 9.01 ms, total: 265 ms\n",
      "Wall time: 5.88 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_documents': [Document(page_content='Creating, inspecting, and deleting Collections Chroma uses collection names in the url, so there are a few restrictions on naming them:', metadata={'source': '3'}),\n",
       "  Document(page_content='Install the Python SDK with pip install \"unstructured[local-inference]\" - If you do not need to process PDFs or images, you can run pip install unstructured Install the following system dependencies if they are not already available on your system. Depending on what document types you\\'re parsing, you may not need all of these. libmagic-dev (filetype detection) poppler-utils (images and PDFs) tesseract-ocr (images and PDFs) libreoffice (MS Office docs) If you are parsing PDFs, run the following to install the detectron2 model, which unstructured uses for layout detection: pip install \"detectron2@git+https://github.com/facebookresearch/detectron2.git@e2ce8dc#egg=detectron2\"', metadata={'source': '0'}),\n",
       "  Document(page_content='Chroma lets you manage collections of embeddings, using the collection primitive.', metadata={'source': '2'}),\n",
       "  Document(page_content='The length of the name must be between 3 and 63 characters. The name must start and end with a lowercase letter or a digit, and it can contain dots, dashes, and underscores in between. The name must not contain two consecutive dots. The name must not be a valid IP address.', metadata={'source': '4'})],\n",
       " 'question': 'What is the detectron repo?',\n",
       " 'output_text': 'https://github.com/facebookresearch/detectron2.git@e2ce8dc#egg=detectron2'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "question = \"What is the detectron repo?\"\n",
    "docs = docsearch.similarity_search(question)\n",
    "chain({\"input_documents\" : docs, \"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5f6466",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "question = \"What are the rules for a name?\"\n",
    "docs = docsearch.similarity_search(question)\n",
    "chain({\"input_documents\" : docs, \"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26c7102",
   "metadata": {},
   "source": [
    "# Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "688888a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Given the following extracted parts of a long document and a question, create a final answer.\n",
    "If you don't know the answer, just say that you \"don't know\". Don't try to make up an answer.\n",
    "\n",
    "Respond in English and Order and fix typos.\n",
    "\n",
    "QUESTION: {question}\n",
    "=========\n",
    "{summaries}\n",
    "=========\n",
    "\n",
    "FINAL ANSWER IN English.\"\"\"\n",
    "Prompt = PromptTemplate(template=template, input_variables=[\"summaries\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d25fab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_with_sources_chain(flan_ul2, chain_type=\"stuff\", prompt=Prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90220799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 102 ms, sys: 96 µs, total: 102 ms\n",
      "Wall time: 2.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_documents': [Document(page_content='The length of the name must be between 3 and 63 characters. The name must start and end with a lowercase letter or a digit, and it can contain dots, dashes, and underscores in between. The name must not contain two consecutive dots. The name must not be a valid IP address.', metadata={'source': '4'}),\n",
       "  Document(page_content='By default, Chains and Agents are stateless, meaning that they treat each incoming query independently. In some applications (chatbots being a GREAT example) it is highly important to remember previous interactions, both at a short term but also at a long term level. The concept of \"Memory\" exists to do exactly that.', metadata={'source': '1'}),\n",
       "  Document(page_content='Creating, inspecting, and deleting Collections Chroma uses collection names in the url, so there are a few restrictions on naming them:', metadata={'source': '3'}),\n",
       "  Document(page_content='Install the Python SDK with pip install \"unstructured[local-inference]\" - If you do not need to process PDFs or images, you can run pip install unstructured Install the following system dependencies if they are not already available on your system. Depending on what document types you\\'re parsing, you may not need all of these. libmagic-dev (filetype detection) poppler-utils (images and PDFs) tesseract-ocr (images and PDFs) libreoffice (MS Office docs) If you are parsing PDFs, run the following to install the detectron2 model, which unstructured uses for layout detection: pip install \"detectron2@git+https://github.com/facebookresearch/detectron2.git@e2ce8dc#egg=detectron2\"', metadata={'source': '0'})],\n",
       " 'question': \"What is today's date?\",\n",
       " 'output_text': \"don't know\"}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "question = \"What is today's date?\"\n",
    "docs = docsearch.similarity_search(question)\n",
    "chain({\"input_documents\" : docs, \"question\": question})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-llm2",
   "language": "python",
   "name": "env-llm2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
